{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef44de2-5f60-4b5e-9b19-26d5ca79865a",
   "metadata": {},
   "source": [
    "Virtual Acoustics and Immersive Audio Workshop - CCRMA Stanford University  \n",
    "31.07.25 - Orchisama Das, Gloria Dal Santo\n",
    "  \n",
    "### L09: Spatial Impulse Response Rendering\n",
    "\n",
    "In this assignment we will \n",
    "- Read FOA SRIRs for a single source-receiver pair in the racquetball court and run SIRR analysis on it.\n",
    "- Output RIR files for 22.1 speaker setup in studio E.\n",
    "- Listen to auralization with `sparta_multiconv` plugin that does multichannel convolution of the dry signal with each of the synthesized RIRs for the loudspeakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023a36c-8bdc-4c25-8626-33130440d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import spaudiopy as spa\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from spatial_audio.sirr import SIRRParameters, SIRR\n",
    "from utils import ms_to_samps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3c9e8-381f-436a-a8af-524e06e3721b",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "Complete the functions `calculate_parameters()`, `process_directional_part()` and `process_frame()`,  in the `SIRR` class. \n",
    "- `calculate_parameters()` should return an object of dataclass `SIRRParameters`. These parameters are then smoothed over time to prevent DoA smearing and phasiness. This is done in the `process()` function. The smoothed parameters are saved in an `SIRRParameters` dataclass called `self.smoothed_parameters`.\n",
    "- `process_directional_part` takes in as input the directional part of the current time-frame. It should use the smoothed DoAs to calculate the VBAP gains for each frequency-bin and each loudspeaker, and return the directional components for each frequency bin and all 22 loudspeakers. The VBAP implementation has been provided in `spatial.py`.\n",
    "- `process_frame()` should return the output signal for the current time frame (of shape `num_loudspeakers, num_frequency_bins`) by decomposing `cur_stft_frame` (of shape `num_ambi_channels, num_frequency_bins`) into direct and diffuse parts, processing them separately and adding them.\n",
    "\n",
    "Read an SRIR you have synthesized in Lecture 7's assignment and generate the loudspeaker signals obtained from SIRR for playback in CCRMA's studio E. Save the first 1.5s of the 22-channel output file. **We are saving 1.5s because my laptop can do 22 simultaneous convolutions in real-time only with such a short signal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07815f-7509-4d14-b6c7-f35f4bfff71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read studio E speaker positions in spherical coordinates\n",
    "\n",
    "ls_layout_path = Path('../data/Week 2/CCRMAStudioEFlippedAzimuth.json').resolve()\n",
    "with open(ls_layout_path) as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    ls_layout = json_data['GenericLayout']['Elements']\n",
    "    num_ls = len(ls_layout)\n",
    "    ls_dirs = np.zeros((num_ls, 3))\n",
    "    for k, ls in enumerate(ls_layout):\n",
    "        ls_dirs[k, 0] = ls['Azimuth']\n",
    "        ls_dirs[k, 1] = ls['Elevation']\n",
    "        ls_dirs[k, 2] = ls['Radius']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8aff8-261c-4796-ac20-e57e09f50b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read B format RIR from source position I and receiver position A\n",
    "src = 'I'\n",
    "rec = 'A'\n",
    "srir_path = Path(f'../data/Week 2/shoe-box-synth-comp/ambi_rec/Bformat_Speaker_src={src}_rec={rec}.wav').resolve()\n",
    "srir, fs = sf.read(str(srir_path))\n",
    "\n",
    "# Truncate RIR to 1.5s\n",
    "trunc_len_ms = 1500\n",
    "trunc_len_samps = ms_to_samps(trunc_len_ms, fs)\n",
    "srir_trunc = srir[:trunc_len_samps, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da54b06-adde-436a-b02c-bc083a0b1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WRITE YOUR CODE HERE ####\n",
    "\n",
    "# create SIRR object\n",
    "\n",
    "# get output signal by calling SIRR's process() function\n",
    "\n",
    "# save the SIRR synthesised RIRs for each speaker in Studio E\n",
    "save_path = Path(f'../data/Week 2/shoe-box-synth-comp/sirr/SIRR_Bformat_Speaker_src={src}_rec={rec}_trunc.wav').resolve()\n",
    "sf.write(str(save_path), output_signal.T, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e096bd-58ab-46b7-ba48-c58f5ef2ae74",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Log the DoAs of each time-frame and for each frequency bin by making use of `DataLogger` in `utils.py`. Save the DoAs in a mat file with the `save_history` function. Load the mat file and plot the DoAs for the 1kHz frequency bin for each time-frame. You can use `spaudiopy`'s `plot.doa` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b350b1d-aa77-4d82-a978-bcb39d3ee529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_doa(freq_bins: ArrayLike, az: ArrayLike, el: NDArray, fs: float, freq_to_plot: float = 1000):\n",
    "    \"\"\"Plot the DOA estimates over several time frames for frequency = freq_to_plot Hz\"\"\"\n",
    "\n",
    "    # find the closest frequency to freq_to_plot\n",
    "    closest_idx = np.argmin(np.abs(freq_bins - freq_to_plot))\n",
    "\n",
    "    # get azimuth and elevation angles\n",
    "    cur_az = az[:, closest_idx]\n",
    "    cur_el = el[:, closest_idx]\n",
    "    cur_r = np.ones_like(freq_bins)\n",
    "    ps = ps = 1 / np.exp(np.linspace(0, 3, len(cur_az)))\n",
    "\n",
    "    # call spaaudiopy's plot.doa function\n",
    "    spa.plot.doa(cur_az, np.pi / 2 - cur_el, ps, fs=fs, ltitle=f'{freq_to_plot}Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc587f6b-6240-429c-b3de-4c8f41b73121",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = Path('../data/Week 2/shoe-box-synth-comp/sirr/').resolve()\n",
    "\n",
    "# Save the estimated DoAs by calling save_history in SIRR\n",
    "\n",
    "# Load the saved DoAs\n",
    "\n",
    "# Plot the saved DoAs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
